{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBegbO9-0UxP",
        "outputId": "f94a4ec2-962b-45df-bb7a-3cbf92374e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pyswarms in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from pyswarms) (25.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.2.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 1ï¸âƒ£ INSTALLS\n",
        "# ============================================================\n",
        "!pip install kagglehub pandas numpy scikit-learn tensorflow pyswarms prettytable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 1 â€” IMPORTS\n",
        "# ============================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pyswarms as ps\n",
        "from pyswarms.single.global_best import GlobalBestPSO\n",
        "from prettytable import PrettyTable\n",
        "import kagglehub\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "kxwbOPE40qKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 2 â€” DOWNLOAD + LOAD + SAMPLE DATASET\n",
        "# ============================================\n",
        "\n",
        "# Download dataset automatically\n",
        "path = kagglehub.dataset_download(\"chethuhn/network-intrusion-dataset\")\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "\n",
        "# Load all CSV files\n",
        "csv_files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".csv\")]\n",
        "print(\"Found CSV files:\", csv_files)\n",
        "\n",
        "df = pd.concat([pd.read_csv(f, low_memory=False) for f in csv_files],\n",
        "               ignore_index=True)\n",
        "\n",
        "print(\"Full dataset shape:\", df.shape)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# ðŸ“Œ RAM SAVING FIX â€“ SAMPLE BEFORE ANY PROCESSING\n",
        "# -------------------------------------------------------\n",
        "SAMPLE_FRACTION = 0.05  # 5% of the data to avoid RAM crash (change to 0.01 if needed)\n",
        "\n",
        "df = df.sample(frac=SAMPLE_FRACTION, random_state=42).reset_index(drop=True)\n",
        "print(\"After sampling:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCBEpMg70wU-",
        "outputId": "aef8ae79-1a34-4a81-a231-61715570dc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'network-intrusion-dataset' dataset.\n",
            "Dataset downloaded to: /kaggle/input/network-intrusion-dataset\n",
            "Found CSV files: ['/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Tuesday-WorkingHours.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Monday-WorkingHours.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Morning.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', '/kaggle/input/network-intrusion-dataset/Wednesday-workingHours.pcap_ISCX.csv']\n",
            "Full dataset shape: (2830743, 79)\n",
            "After sampling: (141537, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 3 â€” CLEANING + PREPROCESSING + SPLIT\n",
        "# ============================================\n",
        "\n",
        "# Standardize column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Convert label to numeric\n",
        "df[\"label\"] = df[\"label\"].astype(\"category\").cat.codes\n",
        "\n",
        "# Replace infinite values\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Drop any rows with NaN\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate X and y\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# ============================================================\n",
        "# FIX: Remove classes with fewer than 2 samples\n",
        "# ============================================================\n",
        "class_counts = y.value_counts()\n",
        "valid_classes = class_counts[class_counts >= 2].index\n",
        "df = df[df[\"label\"].isin(valid_classes)]\n",
        "\n",
        "# Re-separate X and y\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"Classes remaining:\", y.nunique())\n",
        "print(\"Samples per class:\\n\", y.value_counts())\n",
        "\n",
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train / Validation / Test Split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Convert labels to NumPy\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQYwaw03Ed7k",
        "outputId": "bbb1f3da-6377-44dd-e5c5-72e376107440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes remaining: 13\n",
            "Samples per class:\n",
            " label\n",
            "0     113651\n",
            "4      11499\n",
            "10      7877\n",
            "2       6391\n",
            "3        516\n",
            "7        424\n",
            "6        293\n",
            "11       289\n",
            "5        260\n",
            "1         83\n",
            "12        70\n",
            "13        41\n",
            "8          2\n",
            "Name: count, dtype: int64\n",
            "X_train: (113116, 78)\n",
            "X_test: (14140, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 4 â€” EXTREME LEARNING MACHINE CLASS\n",
        "# ============================================\n",
        "\n",
        "class ELM:\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.W = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.b = np.random.randn(self.hidden_dim)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return np.tanh(X @ self.W + self.b)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        H = self.forward(X)\n",
        "        self.beta = np.linalg.pinv(H) @ y\n",
        "\n",
        "    def predict(self, X):\n",
        "        H = self.forward(X)\n",
        "        return (H @ self.beta > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "49NnFxBi1Hnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 5 â€” PSO OPTIMIZATION OF ELM\n",
        "# ============================================\n",
        "\n",
        "X_train_fs = X_train\n",
        "y_train_fs = y_train\n",
        "\n",
        "input_dim = X_train_fs.shape[1]\n",
        "hidden_dim = 120  # same as research paper\n",
        "\n",
        "param_dim = (input_dim * hidden_dim) + hidden_dim\n",
        "\n",
        "def fitness_function(particles):\n",
        "    losses = []\n",
        "    for particle in particles:\n",
        "        # Extract weights + biases\n",
        "        W_flat = particle[:input_dim * hidden_dim]\n",
        "        b_flat = particle[input_dim * hidden_dim:]\n",
        "\n",
        "        W = W_flat.reshape(input_dim, hidden_dim)\n",
        "        b = b_flat\n",
        "\n",
        "        H = np.tanh(X_train_fs @ W + b)\n",
        "        beta = np.linalg.pinv(H) @ y_train_fs\n",
        "        pred = (H @ beta > 0.5).astype(int)\n",
        "\n",
        "        acc = (pred == y_train_fs).mean()\n",
        "        losses.append(1 - acc)\n",
        "\n",
        "    return np.array(losses)\n",
        "\n",
        "# PSO optimizer settings\n",
        "optimizer = GlobalBestPSO(\n",
        "    n_particles=20,\n",
        "    dimensions=param_dim,\n",
        "    options={\"c1\": 2.0, \"c2\": 2.0, \"w\": 0.9}\n",
        ")\n",
        "\n",
        "best_cost, best_pos = optimizer.optimize(fitness_function, iters=10)\n",
        "\n",
        "print(\"PSO optimization complete.\")\n"
      ],
      "metadata": {
        "id": "FJIjKYou1J_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac778b9-a855-4550-a136-f2d7029a4e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-25 13:55:40,646 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 2.0, 'c2': 2.0, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|10/10, best_cost=0.35\n",
            "2025-11-25 14:06:09,687 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.3501096219809753, best pos: [ 2.35631764 -0.74537805  4.5428027  ...  0.40179629  3.78631142\n",
            " -0.29026125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO optimization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 6 â€” FINAL ELM TRAINING\n",
        "# ============================================\n",
        "\n",
        "W_flat = best_pos[:input_dim * hidden_dim]\n",
        "b_flat = best_pos[input_dim * hidden_dim:]\n",
        "\n",
        "W = W_flat.reshape(input_dim, hidden_dim)\n",
        "b = b_flat\n",
        "\n",
        "elm = ELM(input_dim, hidden_dim)\n",
        "elm.W = W\n",
        "elm.b = b\n",
        "\n",
        "elm.fit(X_train_fs, y_train_fs)\n",
        "\n",
        "pred_test = elm.predict(X_test)\n"
      ],
      "metadata": {
        "id": "f9Hm-2OXFwMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 7 â€” EVALUATION\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nCONFUSION MATRIX\")\n",
        "print(confusion_matrix(y_test, pred_test))\n",
        "\n",
        "print(\"\\nCLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test, pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPXUGXH7CJ_3",
        "outputId": "7c7c6e54-91d4-41ab-bf79-37a0df312b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONFUSION MATRIX\n",
            "[[9243 2123    0    0    0    0    0    0    0    0    0    0]\n",
            " [   4    4    0    0    0    0    0    0    0    0    0    0]\n",
            " [   1  638    0    0    0    0    0    0    0    0    0    0]\n",
            " [   3   48    0    0    0    0    0    0    0    0    0    0]\n",
            " [   1 1149    0    0    0    0    0    0    0    0    0    0]\n",
            " [   7   19    0    0    0    0    0    0    0    0    0    0]\n",
            " [   3   27    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0   43    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0  787    0    0    0    0    0    0    0    0    0    0]\n",
            " [  11   18    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    7    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    4    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.90     11366\n",
            "           1       0.00      0.50      0.00         8\n",
            "           2       0.00      0.00      0.00       639\n",
            "           3       0.00      0.00      0.00        51\n",
            "           4       0.00      0.00      0.00      1150\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        30\n",
            "           7       0.00      0.00      0.00        43\n",
            "          10       0.00      0.00      0.00       787\n",
            "          11       0.00      0.00      0.00        29\n",
            "          12       0.00      0.00      0.00         7\n",
            "          13       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.65     14140\n",
            "   macro avg       0.08      0.11      0.07     14140\n",
            "weighted avg       0.80      0.65      0.72     14140\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XylKzCpJGT3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9luW95DCNBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6OsHdvkCP_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aoO57GJyCSXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxTVB-bFCU0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ou51QaDDCW6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}